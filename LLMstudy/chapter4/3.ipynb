{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "import sys\n",
    "# 导入功能模块目录\n",
    "sys.path.append(\"../\")\n",
    "from qa_chain.QA_chain_self import QA_chain_self\n",
    "\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:7890\"\n",
    "\n",
    "app = FastAPI() # 创建 api 对象\n",
    "\n",
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "案。最多使用三句话。尽量使答案简明扼要。总是在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {question}\n",
    "有用的回答:\"\"\"\n",
    "\n",
    "# 定义一个数据模型，用于接收POST请求中的数据\n",
    "class Item(BaseModel):\n",
    "    prompt : str # 用户 prompt\n",
    "    model : str = \"gpt-3.5-turbo\"# 使用的模型\n",
    "    temperature : float = 0.1# 温度系数\n",
    "    if_history : bool = False # 是否使用历史对话功能\n",
    "    # API_Key\n",
    "    api_key: str = None\n",
    "    # Secret_Key\n",
    "    secret_key : str = None\n",
    "    # access_token\n",
    "    access_token: str = None\n",
    "    # APPID\n",
    "    appid : str = None\n",
    "    # APISecret\n",
    "    Spark_api_secret : str = None\n",
    "    # Secret_key\n",
    "    Wenxin_secret_key : str = None\n",
    "    # 数据库路径\n",
    "    db_path : str = \"../../data_base/vector_db/chroma\"\n",
    "    # 源文件路径\n",
    "    file_path : str = \"../../data_base/knowledge_db\"\n",
    "    # prompt template\n",
    "    prompt_template : str = template\n",
    "    # Template 变量\n",
    "    input_variables : list = [\"context\",\"question\"]\n",
    "    # Embdding\n",
    "    embedding : str = \"openai\"\n",
    "    # Top K\n",
    "    top_k : int = 5\n",
    "    # embedding_key\n",
    "    embedding_key : str = None\n",
    "\n",
    "@app.post(\"/answer/\")\n",
    "async def get_response(item: Item):\n",
    "\n",
    "    # 首先确定需要调用的链\n",
    "    if not item.if_history:\n",
    "        # 调用 Chat 链\n",
    "        # return item.embedding_key\n",
    "        if item.embedding_key == None:\n",
    "            item.embedding_key = item.api_key\n",
    "        chain = QA_chain_self(model=item.model, temperature=item.temperature, top_k=item.top_k, file_path=item.file_path, persist_path=item.db_path, \n",
    "                                appid=item.appid, api_key=item.api_key, embedding=item.embedding, template=template, Spark_api_secret=item.Spark_api_secret, Wenxin_secret_key=item.Wenxin_secret_key, embedding_key=item.embedding_key)\n",
    "\n",
    "        response = chain.answer(question = item.prompt)\n",
    "    \n",
    "        return response\n",
    "    \n",
    "    # 由于 API 存在即时性问题，不能支持历史链\n",
    "    else:\n",
    "        return \"API 不支持历史链\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
